\chapter{Conclusion and Outlook}

This thesis explains the implementation of a cloud-native architecture designed for secure, scalable, and distributed computing, with a focus on authentication, authorization, and the deployment of AI models. The primary objective is to address the challenges posed by modern cloud-native environments, particularly in ensuring security, scalability, and the efficient management of distributed workloads. The first major component of this research was to integrate an authentication module using Keycloak with ArgoCD to ensure that only authorized users can access and manage application deployments. Keycloak was chosen because of IAM capabilities that offer SSO and include support of various authentication schemes such as OAuth and OIDC \cite{keycloak_doc}. This approach provide ArgoCD a secure access point and helps in centralizing and streamlining user administration \cite{keycloak_doc}. The second part of the research is to implement authorization using Kubernetes RBAC, to manage fine-grained access control, and make sure that users and services only had the necessary permissions to interact with resources in the cluster \cite{Kubernetes_doc}. The principle of least privilege was implemented by using Kubernetes RBAC in combination with roles, role bindings, cluster roles, and cluster role bindings, which improve the security of the cluster and reduced the potential risk in the cloud-native environment \cite{Kubernetes_doc}. Thus, by automating the process of creating users and assigning roles using RBAC configurations, we can efficiently manage roles and access policies across the cluster \cite{Kubernetes_doc}. The third of this research was the implementation of scalable and distributed architecture for AI models using the Ray framework. Ray is a complete ecosystem for data processing, training , tuning, serving and processing of large-scale AI workloads by enabling autoscaling through Kubernetes HPA \cite{ray_doc}. Integrating KubeRay with the Kubernetes cluster ensured that resources can be dynamically scale based on the computational demand, optimizing the use of both CPU and GPU resources \cite{ray_doc}. This enables to process large datasets and complex AI models in a cloud-native environment with high flexibility and performance \cite{ray_doc}. By addressing critical issues of authentication, authorization, and resource distribution, this report illustrate how cloud-native architectures can be used to achieve security, scalability, and effectively handle distributed workloads. Utilizing tools like Keycloak, Kubernetes RBAC, and Ray helps to address typical issues in cloud-native environments, making the architecture well suited for modern AI-driven applications.

In the future, frameworks such as Apache Spark, Dask, Modin, Optuna, Hyperopt, and TensorFlow Serve will be implemented and compared in order to investigate distributed computing options outside of Ray. The evaluation of these frameworks in this research has been primarily based on documentation; however, the next step will be to use these frameworks to implement cloud-native architectures. This experimentation will allow a thorough comparison of their performance in terms of scalability, resource efficiency, ease of integration and overall system responsiveness. Comparing these frameworks with Ray for large datasets and using advanced libraries to train ML and DL models will provide valuable insights into bottlenecks, strengths and weaknesses in managing distributed AI workloads. This future research will provide a more comprehensive understanding of these tools and help to further optimise the deployment of scalable AI models in cloud-native architectures.